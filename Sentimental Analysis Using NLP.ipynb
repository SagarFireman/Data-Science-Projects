{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c916862a",
   "metadata": {},
   "source": [
    "Librabry Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0610c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ddaa4",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f7e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\DATA SCIENCE\\data science\\9. Natural Language Processing\\Restaurant_Reviews.tsv\",delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ecb10",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70a1d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd28a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6859792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    0\n",
      "Liked     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8912adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df['Liked'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c431958",
   "metadata": {},
   "source": [
    "Downloading Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fb23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\agala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "a=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6a8f2",
   "metadata": {},
   "source": [
    "Cleaning the Data Using Stopwords, Stemming and Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f995d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "token\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem('lovely'))\n",
    "print(ps.stem('tokenization'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1b7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0dc5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub('[^a-zA-Z]',' ', df['Review'][i])\n",
    "    review = review.lower()\n",
    "    dp = nlp(review)\n",
    "    dpa = [token.lemma_ for token in dp]\n",
    "    v = [ps.stem(token) for token in dpa if token not in a]\n",
    "    v = ' '.join(v)\n",
    "    lst1.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d9e7e",
   "metadata": {},
   "source": [
    "Vectorization and Selection of x and y Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98abdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(lst1).toarray()\n",
    "y=df['Liked'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b3c14",
   "metadata": {},
   "source": [
    "Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1583dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "033f707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be689a7",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809c06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  43]\n",
      " [ 20 107]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88a8ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80       173\n",
      "           1       0.71      0.84      0.77       127\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.79      0.80      0.79       300\n",
      "weighted avg       0.80      0.79      0.79       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b11fe",
   "metadata": {},
   "source": [
    "Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a06a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy is:  0.7969999999999999\n",
      "random forest accuracy is:  0.758\n",
      "svm accuracy is:  0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "print('logistic regression accuracy is: ',cross_val_score(log,x,y,cv=10,scoring='accuracy').mean())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "print('random forest accuracy is: ',cross_val_score(rfc,x,y,cv=10,scoring='accuracy').mean())\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "print('svm accuracy is: ',cross_val_score(classifier,x,y,cv=10,scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569cc41",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce6e7b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'fit_prior': False}\n",
      "0.7785714285714287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0],\n",
    "              'fit_prior': [True, False]}\n",
    "\n",
    "# Create the Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c641074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.3571938800686731, 'fit_prior': False}\n",
      "0.7785714285714287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_dist = {'alpha': uniform(0.1, 2.0),\n",
    "              'fit_prior': [True, False]}\n",
    "\n",
    "# Create the Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(classifier, param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f5156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
